{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['lang', 'source_code', 'tags', 'lang_cluster', 'src_uid', 'code_uid', 'difficulty', 'exec_outcome', 'task_id', 'hidden_unit_tests', 'unittests'],\n",
       "    num_rows: 45\n",
       "})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./yunzhe/1002_submissions_results_H_Java.jsonl\"\n",
    "ds = datasets.load_dataset(\"json\", data_files=path, split=\"train\").filter(lambda x:x['lang']=='Java 8')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for d in ds:\n",
    "    src_uid = d['src_uid']\n",
    "    code_uid = d['code_uid']\n",
    "    all_pass = True if all(item['exec_outcome'] == 'PASSED' for item in d['unittests']) else False\n",
    "    print(f\"{all_pass}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['lang', 'source_code', 'lang_cluster', 'tags', 'code_uid', 'src_uid', 'difficulty', 'exec_outcome', 'task_id', 'unittests', 'is_correct'],\n",
      "    num_rows: 106\n",
      "})\n",
      "106\n"
     ]
    }
   ],
   "source": [
    "path = \"./yunzhe/java_valid_code.jsonl\"\n",
    "ds_java = datasets.load_dataset(\"json\", data_files=path, split=\"train\").filter(lambda x:x['lang']=='Java 8')\n",
    "print(ds_java)\n",
    "# for d in ds_java:\n",
    "#     src_uid = d['src_uid']\n",
    "#     code_uid = d['code_uid']\n",
    "#     # all_pass = d['pass_rate'] == 100\n",
    "#     print(f\"{src_uid}\")\n",
    "print(len(set(ds_java['src_uid'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "30/45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48447131f27445268665c501ac8788c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3214de9634174f9282579071c09ededb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e345864a824116a581c22629cfca43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "406c1f6834af4d7e90754dd112da7330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/45 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['lang', 'source_code', 'tags', 'lang_cluster', 'src_uid', 'code_uid', 'difficulty', 'exec_outcome', 'task_id', 'hidden_unit_tests', 'unittests', 'pass_rate', 'mean_cpu_time', 'mean_peak_mem'],\n",
       "    num_rows: 45\n",
       "})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./test_java.jsonl\"\n",
    "ds_mine = datasets.load_dataset(\"json\", data_files=path, split=\"train\").filter(lambda x:x['lang']=='Java 8')\n",
    "ds_mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for d in ds_mine:\n",
    "    src_uid = d['src_uid']\n",
    "    code_uid = d['code_uid']\n",
    "    all_pass = d['pass_rate'] == 100\n",
    "    print(f\"{all_pass}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-02 23:35:49 - 103545798.py - INFO - start screening and sampling from:\n",
      " - task_ds:./yunzhe/descriptions_0822.jsonl\n",
      " - submi_ds:./yunzhe/valid_submission_samples.jsonl\n",
      " - testcase_ds:./yunzhe/testcases_0822.jsonl\n",
      "all the output files will be placed at:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49\n",
      "2023-10-02 23:35:49 - 103545798.py - INFO - start screening and sampling from:\n",
      " - task_ds:./yunzhe/descriptions_0822.jsonl\n",
      " - submi_ds:./yunzhe/valid_submission_samples.jsonl\n",
      " - testcase_ds:./yunzhe/testcases_0822.jsonl\n",
      "all the output files will be placed at:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49\n",
      "2023-10-02 23:35:49 - 103545798.py - INFO - start screening and sampling from:\n",
      " - task_ds:./yunzhe/descriptions_0822.jsonl\n",
      " - submi_ds:./yunzhe/valid_submission_samples.jsonl\n",
      " - testcase_ds:./yunzhe/testcases_0822.jsonl\n",
      "all the output files will be placed at:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49\n",
      "2023-10-02 23:35:49 - 103545798.py - INFO - start screening and sampling from:\n",
      " - task_ds:./yunzhe/descriptions_0822.jsonl\n",
      " - submi_ds:./yunzhe/valid_submission_samples.jsonl\n",
      " - testcase_ds:./yunzhe/testcases_0822.jsonl\n",
      "all the output files will be placed at:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49\n",
      "2023-10-02 23:35:49 - 103545798.py - INFO - start screening and sampling from:\n",
      " - task_ds:./yunzhe/descriptions_0822.jsonl\n",
      " - submi_ds:./yunzhe/valid_submission_samples.jsonl\n",
      " - testcase_ds:./yunzhe/testcases_0822.jsonl\n",
      "all the output files will be placed at:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49\n",
      "2023-10-02 23:35:49 - 103545798.py - INFO - start screening and sampling from:\n",
      " - task_ds:./yunzhe/descriptions_0822.jsonl\n",
      " - submi_ds:./yunzhe/valid_submission_samples.jsonl\n",
      " - testcase_ds:./yunzhe/testcases_0822.jsonl\n",
      "all the output files will be placed at:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49\n",
      "2023-10-02 23:35:49 - 103545798.py - INFO - screen1 start, screening submissions implemented by focal langs:['GNU C', 'GNU C++', 'Mono C#', 'Python 3'], and with testcases\n",
      "2023-10-02 23:35:49 - 103545798.py - INFO - screen1 start, screening submissions implemented by focal langs:['GNU C', 'GNU C++', 'Mono C#', 'Python 3'], and with testcases\n",
      "2023-10-02 23:35:49 - 103545798.py - INFO - screen1 start, screening submissions implemented by focal langs:['GNU C', 'GNU C++', 'Mono C#', 'Python 3'], and with testcases\n",
      "2023-10-02 23:35:49 - 103545798.py - INFO - screen1 start, screening submissions implemented by focal langs:['GNU C', 'GNU C++', 'Mono C#', 'Python 3'], and with testcases\n",
      "2023-10-02 23:35:49 - 103545798.py - INFO - screen1 start, screening submissions implemented by focal langs:['GNU C', 'GNU C++', 'Mono C#', 'Python 3'], and with testcases\n",
      "2023-10-02 23:35:49 - 103545798.py - INFO - screen1 start, screening submissions implemented by focal langs:['GNU C', 'GNU C++', 'Mono C#', 'Python 3'], and with testcases\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d89851eabf24cf6b2dbbb8ae069e661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9046c6053a54036ad72801618d49f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a9ea3ed7b94951ad68afa818aeea2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-02 23:36:08 - 103545798.py - INFO - screen1 finished, output files:\n",
      " - screened1_submi_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/screen1_submissions.jsonl\n",
      " - screened1_submi_per_srcuidlang_table:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/screen1_submissions_per_srcuidlang.csv\n",
      "2023-10-02 23:36:08 - 103545798.py - INFO - screen1 finished, output files:\n",
      " - screened1_submi_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/screen1_submissions.jsonl\n",
      " - screened1_submi_per_srcuidlang_table:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/screen1_submissions_per_srcuidlang.csv\n",
      "2023-10-02 23:36:08 - 103545798.py - INFO - screen1 finished, output files:\n",
      " - screened1_submi_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/screen1_submissions.jsonl\n",
      " - screened1_submi_per_srcuidlang_table:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/screen1_submissions_per_srcuidlang.csv\n",
      "2023-10-02 23:36:08 - 103545798.py - INFO - screen1 finished, output files:\n",
      " - screened1_submi_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/screen1_submissions.jsonl\n",
      " - screened1_submi_per_srcuidlang_table:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/screen1_submissions_per_srcuidlang.csv\n",
      "2023-10-02 23:36:08 - 103545798.py - INFO - screen1 finished, output files:\n",
      " - screened1_submi_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/screen1_submissions.jsonl\n",
      " - screened1_submi_per_srcuidlang_table:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/screen1_submissions_per_srcuidlang.csv\n",
      "2023-10-02 23:36:08 - 103545798.py - INFO - screen1 finished, output files:\n",
      " - screened1_submi_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/screen1_submissions.jsonl\n",
      " - screened1_submi_per_srcuidlang_table:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/screen1_submissions_per_srcuidlang.csv\n",
      "2023-10-02 23:36:08 - 103545798.py - INFO - screen2 start, screening submissions with submi_cnt_per_task>4, testcase_cnt_per_task>20, task_cnt_per_lang>30\n",
      "2023-10-02 23:36:08 - 103545798.py - INFO - screen2 start, screening submissions with submi_cnt_per_task>4, testcase_cnt_per_task>20, task_cnt_per_lang>30\n",
      "2023-10-02 23:36:08 - 103545798.py - INFO - screen2 start, screening submissions with submi_cnt_per_task>4, testcase_cnt_per_task>20, task_cnt_per_lang>30\n",
      "2023-10-02 23:36:08 - 103545798.py - INFO - screen2 start, screening submissions with submi_cnt_per_task>4, testcase_cnt_per_task>20, task_cnt_per_lang>30\n",
      "2023-10-02 23:36:08 - 103545798.py - INFO - screen2 start, screening submissions with submi_cnt_per_task>4, testcase_cnt_per_task>20, task_cnt_per_lang>30\n",
      "2023-10-02 23:36:08 - 103545798.py - INFO - screen2 start, screening submissions with submi_cnt_per_task>4, testcase_cnt_per_task>20, task_cnt_per_lang>30\n",
      "2023-10-02 23:36:16 - 103545798.py - INFO - screen2 finished, output files:\n",
      " - screened2_submi_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/screen2_submissions.jsonl\n",
      " - srcuidlang_table:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/screen2_srcuidlang_table.csv\n",
      "2023-10-02 23:36:16 - 103545798.py - INFO - screen2 finished, output files:\n",
      " - screened2_submi_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/screen2_submissions.jsonl\n",
      " - srcuidlang_table:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/screen2_srcuidlang_table.csv\n",
      "2023-10-02 23:36:16 - 103545798.py - INFO - screen2 finished, output files:\n",
      " - screened2_submi_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/screen2_submissions.jsonl\n",
      " - srcuidlang_table:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/screen2_srcuidlang_table.csv\n",
      "2023-10-02 23:36:16 - 103545798.py - INFO - screen2 finished, output files:\n",
      " - screened2_submi_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/screen2_submissions.jsonl\n",
      " - srcuidlang_table:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/screen2_srcuidlang_table.csv\n",
      "2023-10-02 23:36:16 - 103545798.py - INFO - screen2 finished, output files:\n",
      " - screened2_submi_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/screen2_submissions.jsonl\n",
      " - srcuidlang_table:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/screen2_srcuidlang_table.csv\n",
      "2023-10-02 23:36:16 - 103545798.py - INFO - screen2 finished, output files:\n",
      " - screened2_submi_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/screen2_submissions.jsonl\n",
      " - srcuidlang_table:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/screen2_srcuidlang_table.csv\n",
      "2023-10-02 23:36:16 - 103545798.py - INFO - sampling start, sampling 30 tasks per lang, and None submissions per task\n",
      "2023-10-02 23:36:16 - 103545798.py - INFO - sampling start, sampling 30 tasks per lang, and None submissions per task\n",
      "2023-10-02 23:36:16 - 103545798.py - INFO - sampling start, sampling 30 tasks per lang, and None submissions per task\n",
      "2023-10-02 23:36:16 - 103545798.py - INFO - sampling start, sampling 30 tasks per lang, and None submissions per task\n",
      "2023-10-02 23:36:16 - 103545798.py - INFO - sampling start, sampling 30 tasks per lang, and None submissions per task\n",
      "2023-10-02 23:36:16 - 103545798.py - INFO - sampling start, sampling 30 tasks per lang, and None submissions per task\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNU C\n",
      "Mono C#\n",
      "Python 3\n",
      "GNU C++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-02 23:38:13 - 103545798.py - INFO - sampling finished, output files:\n",
      " - sampled_task_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/sampled_tasks.jsonl\n",
      " - sampled_submi_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/sampled_submissions.jsonl\n",
      "2023-10-02 23:38:13 - 103545798.py - INFO - sampling finished, output files:\n",
      " - sampled_task_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/sampled_tasks.jsonl\n",
      " - sampled_submi_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/sampled_submissions.jsonl\n",
      "2023-10-02 23:38:13 - 103545798.py - INFO - sampling finished, output files:\n",
      " - sampled_task_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/sampled_tasks.jsonl\n",
      " - sampled_submi_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/sampled_submissions.jsonl\n",
      "2023-10-02 23:38:13 - 103545798.py - INFO - sampling finished, output files:\n",
      " - sampled_task_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/sampled_tasks.jsonl\n",
      " - sampled_submi_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/sampled_submissions.jsonl\n",
      "2023-10-02 23:38:13 - 103545798.py - INFO - sampling finished, output files:\n",
      " - sampled_task_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/sampled_tasks.jsonl\n",
      " - sampled_submi_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/sampled_submissions.jsonl\n",
      "2023-10-02 23:38:13 - 103545798.py - INFO - sampling finished, output files:\n",
      " - sampled_task_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/sampled_tasks.jsonl\n",
      " - sampled_submi_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/sampled_submissions.jsonl\n",
      "2023-10-02 23:38:13 - 103545798.py - INFO - all the output files are placed at:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49\n",
      "2023-10-02 23:38:13 - 103545798.py - INFO - all the output files are placed at:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49\n",
      "2023-10-02 23:38:13 - 103545798.py - INFO - all the output files are placed at:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49\n",
      "2023-10-02 23:38:13 - 103545798.py - INFO - all the output files are placed at:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49\n",
      "2023-10-02 23:38:13 - 103545798.py - INFO - all the output files are placed at:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49\n",
      "2023-10-02 23:38:13 - 103545798.py - INFO - all the output files are placed at:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49\n",
      "2023-10-02 23:38:13 - 103545798.py - INFO - sampling finished, output files:\n",
      " - sampled_task_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/sampled_tasks.jsonl\n",
      " - sampled_submi_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/sampled_submissions.jsonl\n",
      "2023-10-02 23:38:13 - 103545798.py - INFO - sampling finished, output files:\n",
      " - sampled_task_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/sampled_tasks.jsonl\n",
      " - sampled_submi_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/sampled_submissions.jsonl\n",
      "2023-10-02 23:38:13 - 103545798.py - INFO - sampling finished, output files:\n",
      " - sampled_task_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/sampled_tasks.jsonl\n",
      " - sampled_submi_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/sampled_submissions.jsonl\n",
      "2023-10-02 23:38:13 - 103545798.py - INFO - sampling finished, output files:\n",
      " - sampled_task_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/sampled_tasks.jsonl\n",
      " - sampled_submi_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/sampled_submissions.jsonl\n",
      "2023-10-02 23:38:13 - 103545798.py - INFO - sampling finished, output files:\n",
      " - sampled_task_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/sampled_tasks.jsonl\n",
      " - sampled_submi_ds:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49/sampled_submissions.jsonl\n",
      "2023-10-02 23:38:13 - 103545798.py - INFO - all the output files are placed at:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49\n",
      "2023-10-02 23:38:13 - 103545798.py - INFO - all the output files are placed at:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49\n",
      "2023-10-02 23:38:13 - 103545798.py - INFO - all the output files are placed at:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49\n",
      "2023-10-02 23:38:13 - 103545798.py - INFO - all the output files are placed at:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49\n",
      "2023-10-02 23:38:13 - 103545798.py - INFO - all the output files are placed at:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49\n",
      "2023-10-02 23:38:13 - 103545798.py - INFO - all the output files are placed at:/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-10-02_23:35:49\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import logging\n",
    "import datetime\n",
    "# screen1\n",
    "def screen_submi_by_focallang_with_testcases(focallang:list, submi_ds_path, testcase_ds, output_submi_ds_path):\n",
    "    \"\"\"从yunzhe的submi数据集中筛选出四种语言的提交，并选出其中有测试用例的，初步得到optimization任务的submi数据集\"\"\"\n",
    "    srcuids_with_testcases = json.loads(open(testcase_ds).readline()).keys()\n",
    "    with open(submi_ds_path) as in_f, open(output_submi_ds_path, \"w\") as out_f:\n",
    "        for line in in_f:\n",
    "            data = json.loads(line)\n",
    "            if any(\n",
    "                data['lang']==interested_lang for interested_lang in focallang\n",
    "            ) and any(\n",
    "                data['src_uid']==srcuid for srcuid in srcuids_with_testcases\n",
    "            ):\n",
    "                json.dump(data, out_f)\n",
    "                out_f.write('\\n')\n",
    "def cal_subminum_per_srcuidlang(submi_ds_path, output_table_path):\n",
    "    \"\"\"将submi jsonl数据集转化为纵轴为srcuid，横轴为lang，entry为submi_num的表格并存储，方便人工检视数据\"\"\"\n",
    "    submi_ds = datasets.load_dataset(\"json\", data_files=str(submi_ds_path), split=\"train\")\n",
    "    submi_srcuids = set(submi_ds['src_uid'])\n",
    "    submi_langs = set(submi_ds['lang'])\n",
    "    subminum_per_srcuidlang_dict = {srcuid: {lang: 0 for lang in submi_langs} for srcuid in submi_srcuids}\n",
    "    for data in submi_ds:\n",
    "        subminum_per_srcuidlang_dict[data['src_uid']][data['lang']] += 1\n",
    "    subminum_per_srcuidlang_df = pd.DataFrame(subminum_per_srcuidlang_dict).T\n",
    "    subminum_per_srcuidlang_df.to_csv(output_table_path, index=True)\n",
    "    return subminum_per_srcuidlang_dict\n",
    "\n",
    "# screen2\n",
    "def screen_ds_by_submicnt_and_testcasecnt_and_taskcnt(submi_per_srcuidlang_table_path, task_ds_path, submi_ds_path, testcase_ds_path, SUMBMI_CNT_THRESHOLD, TESTCASE_CNT_THRESHOLD, TASK_CNT_THRESHOLD, screened2_submi_ds_path, output_table_path):\n",
    "    submi_per_srcuidlang_table = pd.read_csv(submi_per_srcuidlang_table_path, index_col=0)\n",
    "    screened_srcuidlang_table = pd.DataFrame([],columns=['lang', 'srcuid', 'submi_cnt', 'testcase_cnt'])\n",
    "    testcases_json = json.load(open(testcase_ds_path))\n",
    "    # leverage submi_per_srcuidlang_table to build a table where (lang, srcuid) are the joint key, then use this table to execute screening\n",
    "    for lang in submi_per_srcuidlang_table.columns:\n",
    "        for srcuid in submi_per_srcuidlang_table.index:\n",
    "            submi_cnt = submi_per_srcuidlang_table.loc[srcuid, lang]\n",
    "            testcase_cnt = len(testcases_json[srcuid])\n",
    "            if submi_cnt > SUMBMI_CNT_THRESHOLD and testcase_cnt > TESTCASE_CNT_THRESHOLD:\n",
    "                screened_srcuidlang_table.loc[len(screened_srcuidlang_table)] = {'lang': lang, 'srcuid': srcuid, 'submi_cnt': submi_cnt, 'testcase_cnt': testcase_cnt}\n",
    "\n",
    "    tasksnum_per_lang = screened_srcuidlang_table.groupby('lang')['srcuid'].count()\n",
    "    for lang in screened_srcuidlang_table['lang'].unique():\n",
    "        if tasksnum_per_lang.loc[lang] < TASK_CNT_THRESHOLD:\n",
    "            screened_srcuidlang_table.drop(index=screened_srcuidlang_table[screened_srcuidlang_table['lang']==lang].index, inplace=True)\n",
    "    screened_srcuidlang_table.to_csv(output_table_path, index=False)\n",
    "    # then update datasets according to the screened table\n",
    "    with open(task_ds_path) as in_f, open(save_dir / Path(\"screen2_tasks.jsonl\"), \"w\") as out_f:\n",
    "        for line in in_f:\n",
    "            data = json.loads(line)\n",
    "            if data['src_uid'] in screened_srcuidlang_table['srcuid'].unique():\n",
    "                json.dump(data, out_f)\n",
    "                out_f.write('\\n')\n",
    "    with open(testcase_ds_path) as in_f, open(save_dir / Path(\"screen2_testcases.jsonl\"), \"w\") as out_f:\n",
    "        data = json.load(in_f)\n",
    "        output_data = {}\n",
    "        for (srcuid, testcases) in data.items():\n",
    "            if srcuid not in screened_srcuidlang_table['srcuid'].unique():\n",
    "                output_data[srcuid] = testcases\n",
    "        json.dump(data, out_f)\n",
    "    with open(submi_ds_path) as in_f, open(screened2_submi_ds_path, \"w\") as out_f:\n",
    "        for line in in_f:\n",
    "            data = json.loads(line)\n",
    "            if data['src_uid'] in screened_srcuidlang_table['srcuid'].unique() and data['lang'] in screened_srcuidlang_table['lang'].unique():\n",
    "                json.dump(data, out_f)\n",
    "                out_f.write('\\n')\n",
    "# sample\n",
    "def sample_task_by_timememory(srcuidlang_table_path, task_ds_path, task_tmp_dir, sampled_task_ds_path, sample_threshold):\n",
    "    if not os.path.exists(task_tmp_dir):\n",
    "        os.mkdir(task_tmp_dir)\n",
    "\n",
    "    parse_num = lambda s: float(re.findall(r\"\\d+\", s)[0])\n",
    "    srcuidlang_table = pd.read_csv(srcuidlang_table_path)\n",
    "    for lang in srcuidlang_table['lang'].unique():\n",
    "        task_df = pd.DataFrame([], columns=['src_uid', 'difficulty', 'time_limit(seconds)', 'memory_limit(megabytes)'])\n",
    "        with open(task_ds_path) as f:\n",
    "            for line in f:\n",
    "                data = json.loads(line)\n",
    "                if data['src_uid'] in srcuidlang_table[srcuidlang_table['lang']==lang]['srcuid'].unique():\n",
    "                    task_df.loc[len(task_df)] = [data['src_uid'], parse_num(data['difficulty']), parse_num(data['time_limit']), parse_num(data['memory_limit'])]\n",
    "        # 对task_df按difficulty，time_limit和memory_limit分布采样，每种语言采样50个task\n",
    "        group_sample_num = 0\n",
    "        while True:\n",
    "            group_sample_num += 1\n",
    "            sampled_df = task_df.groupby('time_limit(seconds)').apply(\n",
    "                lambda x: x.groupby('memory_limit(megabytes)').apply(\n",
    "                    lambda x: x.sample(n=min(group_sample_num,x.shape[0]))\n",
    "                )\n",
    "            )\n",
    "            if sampled_df.shape[0] >=sample_threshold:\n",
    "                break\n",
    "        sampled_df.to_csv(str(task_tmp_dir / Path(f\"{lang}_sampled_task.csv\")), index=False)\n",
    "    # 更新task数据集\n",
    "    if os.path.exists(sampled_task_ds_path):\n",
    "        os.remove(sampled_task_ds_path)\n",
    "        print(\"deleted\")\n",
    "    files = os.listdir(task_tmp_dir)\n",
    "    sampled_srcuids = set()\n",
    "    for lang_srcuid_file in files: # 拿到每一个语言的筛选好的任务文件\n",
    "        lang = lang_srcuid_file.split('_')[0]\n",
    "        for sampled_srcuid in pd.read_csv(f\"{task_tmp_dir}/{lang_srcuid_file}\")['src_uid']:# 从筛选好的task文件中找到每一条srcuid\n",
    "            sampled_srcuids.add(sampled_srcuid)\n",
    "\n",
    "    with open(task_ds_path) as in_f, open(sampled_task_ds_path,'w') as out_f:\n",
    "        for line in in_f:\n",
    "            data = json.loads(line)\n",
    "            if data['src_uid'] in sampled_srcuids:\n",
    "                json.dump(data, out_f)\n",
    "                out_f.write('\\n')\n",
    "def sample_submi_random(task_tmp_dir, screened_submi_ds_path, sampled_submi_ds_path, SAMPLE_NUM=None):\n",
    "    if os.path.exists(sampled_submi_ds_path):\n",
    "        os.remove(sampled_submi_ds_path)\n",
    "        print(\"deleted\")\n",
    "    files = os.listdir(task_tmp_dir)\n",
    "\n",
    "    for lang_srcuid_file in files: # 拿到每一个语言的筛选好的任务文件\n",
    "        lang = lang_srcuid_file.split('_')[0]\n",
    "        print(lang)\n",
    "        for sampled_srcuid in pd.read_csv(f\"{task_tmp_dir}/{lang_srcuid_file}\")['src_uid']:# 从筛选好的task文件中找到每一条srcuid\n",
    "            with open(screened_submi_ds_path) as in_f, open(sampled_submi_ds_path, 'a') as out_f: \n",
    "                sample_cnt = 0\n",
    "                for line in in_f: # 对该题目的每一个题解，选取前SAMPLE_NUM个submi，作为最终数据集\n",
    "                    data = json.loads(line)\n",
    "                    if data['lang'] == lang and data['src_uid'] == sampled_srcuid:\n",
    "                        json.dump(data, out_f)\n",
    "                        out_f.write('\\n')\n",
    "                        sample_cnt+=1\n",
    "                        if SAMPLE_NUM is not None:\n",
    "                            if sample_cnt >= SAMPLE_NUM:\n",
    "                                break\n",
    "\n",
    "curdir = Path(os.path.abspath('')) # 如果是py文件，用Path(__file__).parent获取当前文件的目录路径\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "save_dir = curdir / Path(f\"screened_sampled_dataset_{timestamp}\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)# 如果多级目录不存在，递归创建\n",
    "\n",
    "log_file_path = save_dir / Path(\"data_screening_sampling.log\")\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter(fmt='%(asctime)s - %(filename)s - %(levelname)s - %(message)s',\n",
    "                                datefmt='%Y-%m-%d %H:%M:%S')\n",
    "file_handler = logging.FileHandler(filename=log_file_path, mode='w', encoding='utf-8')\n",
    "file_handler.setLevel(logging.INFO)\n",
    "file_handler.setFormatter(formatter)\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setLevel(logging.INFO)\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(stream_handler)\n",
    "\n",
    "\n",
    "task_ds_path = \"./yunzhe/descriptions_0822.jsonl\"\n",
    "submi_ds_path = \"./yunzhe/valid_submission_samples.jsonl\"\n",
    "testcase_ds_path = \"./yunzhe/testcases_0822.jsonl\"\n",
    "\n",
    "logging.info(f\"start screening and sampling from:\\n - task_ds:{task_ds_path}\\n - submi_ds:{submi_ds_path}\\n - testcase_ds:{testcase_ds_path}\\nall the output files will be placed at:{save_dir}\")\n",
    "\n",
    "# screen 1: 从yunzhe的submi数据集中筛选出四种语言的提交，并选出其中有测试用例的，初步得到optimization任务的submi数据集\n",
    "focal_langs = ['GNU C', 'GNU C++', 'Mono C#', 'Python 3']\n",
    "screened1_submi_ds_path = save_dir / Path(\"screen1_submissions.jsonl\")\n",
    "screened1_submi_per_srcuidlang_table_path = save_dir / Path(\"screen1_submissions_per_srcuidlang.csv\")\n",
    "logging.info(f\"screen1 start, screening submissions implemented by focal langs:{focal_langs}, and with testcases\")\n",
    "screen_submi_by_focallang_with_testcases(focal_langs, submi_ds_path, testcase_ds_path, screened1_submi_ds_path)\n",
    "cal_subminum_per_srcuidlang(screened1_submi_ds_path, screened1_submi_per_srcuidlang_table_path)\n",
    "logging.info(f\"screen1 finished, output files:\\n - screened1_submi_ds:{screened1_submi_ds_path}\\n - screened1_submi_per_srcuidlang_table:{screened1_submi_per_srcuidlang_table_path}\")\n",
    "\n",
    "#screen 2: 从screen1的submi数据集中筛选出submi数大于10，testcase数大于20，task数大于10的，得到最终的submi数据集\n",
    "SUMBMI_CNT_THRESHOLD = 4 # 一个task(srcuid)的submissions数大于该阈值才被考虑，因为submission多才较好的能体现人类水平分布\n",
    "TESTCASE_CNT_THRESHOLD = 20 # 一个task(srcuid)的testcase数大于该阈值才被考虑，因为testcase多才能在我们平均的方法里表现算法的综合性能\n",
    "TASK_CNT_THRESHOLD = 30 #100 一个lang下的task数大于该阈值才被考虑，因为task多才能表现LLM在该语言下的综合optimization性能\n",
    "srcuidlang_table_path = save_dir / Path(\"screen2_srcuidlang_table.csv\")\n",
    "screened2_submi_ds_path = save_dir / Path(\"screen2_submissions.jsonl\")\n",
    "logging.info(f\"screen2 start, screening submissions with submi_cnt_per_task>{SUMBMI_CNT_THRESHOLD}, testcase_cnt_per_task>{TESTCASE_CNT_THRESHOLD}, task_cnt_per_lang>{TASK_CNT_THRESHOLD}\")\n",
    "screen_ds_by_submicnt_and_testcasecnt_and_taskcnt(screened1_submi_per_srcuidlang_table_path, task_ds_path, screened1_submi_ds_path, testcase_ds_path, SUMBMI_CNT_THRESHOLD, TESTCASE_CNT_THRESHOLD, TASK_CNT_THRESHOLD, screened2_submi_ds_path, srcuidlang_table_path)\n",
    "logging.info(f\"screen2 finished, output files:\\n - screened2_submi_ds:{screened2_submi_ds_path}\\n - srcuidlang_table:{srcuidlang_table_path}\")\n",
    "\n",
    "#sample: 从screen2的task数据集中采样每种语言至少50个task，每个task采样10个submissions，得到最终的task和submi数据集\n",
    "SAMPLE_TASK_NUM = 30 # 每种语言采样【至少】50个task(和TASK_CNT_THRESHOLD务必对应，至少不能比TASK_CNT_THRESHOLD大)\n",
    "SAMPLE_SUBMI_NUM = None # 10 #每个task采样【准确】10个submissions\n",
    "task_tmp_dir = save_dir / Path(f\"sample{SAMPLE_TASK_NUM}task_per_lang\")\n",
    "screened_task_ds_path = save_dir / Path(\"screen2_tasks.jsonl\")\n",
    "sampled_task_ds_path = save_dir / Path(\"sampled_tasks.jsonl\")\n",
    "sampled_submi_ds_path = save_dir / Path(\"sampled_submissions.jsonl\")\n",
    "logging.info(f\"sampling start, sampling {SAMPLE_TASK_NUM} tasks per lang, and {SAMPLE_SUBMI_NUM} submissions per task\")\n",
    "sample_task_by_timememory(srcuidlang_table_path, screened_task_ds_path, task_tmp_dir, sampled_task_ds_path, SAMPLE_TASK_NUM)\n",
    "sample_submi_random(task_tmp_dir, screened2_submi_ds_path, sampled_submi_ds_path, SAMPLE_SUBMI_NUM)\n",
    "logging.info(f\"sampling finished, output files:\\n - sampled_task_ds:{sampled_task_ds_path}\\n - sampled_submi_ds:{sampled_submi_ds_path}\")\n",
    "logging.info(f\"all the output files are placed at:{save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(focal_java_submi_ds['src_uid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 570456, 6523)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def how_many_data_do_we_have(srcuidlang_table_path):\n",
    "    srcuidlang_table = pd.read_csv(srcuidlang_table_path)\n",
    "    inference_data_num = len(srcuidlang_table.index)# 有多少条task就有多少个inference数据\n",
    "    baseline_exec_data_num = sum([submi_num * test_num for submi_num, test_num in zip(srcuidlang_table['submi_cnt'], srcuidlang_table['testcase_cnt'])])\n",
    "    LLM_exec_data_num = sum([test_num for test_num in srcuidlang_table['testcase_cnt']])# 有多少个testcase就有多少个LLM推理结果需要执行的数据\n",
    "    return inference_data_num, baseline_exec_data_num, LLM_exec_data_num\n",
    "\n",
    "how_many_data_do_we_have(srcuidlang_table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 2359.00it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 328.60it/s]\n",
      "Generating train split: 320 examples [00:00, 6152.43 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lang': 'GNU C',\n",
       " 'source_code': '#include <stdio.h>\\n\\nint knights[100500], n;\\n\\nchar check(int k) {\\n    int start, j;\\n    if(n / k < 3)\\n        return 0;\\n    for(start = 0; start < k; start++) {\\n        char isHappy = 1;\\n        for(j = start; isHappy && j < n; j += k) {\\n            if(knights[j] == 0) {\\n                isHappy = 0;\\n            }\\n        }\\n        if(isHappy)\\n            return 1;\\n    }\\n    return 0;\\n}\\n\\nint main() {\\n    int i, j;\\n    scanf(\"%d\", &n);\\n    for(i = 0; i < n; i++) {\\n        scanf(\"%d\", knights + i);\\n    }\\n    for(i = 1; (long long)(i) * i <= n; i++) {\\n        if(n % i)\\n            continue;\\n        if(check(i) || check(n / i)) {\\n            puts(\"YES\");\\n            return 0;\\n        }\\n    }\\n    puts(\"NO\");\\n    return 0;\\n}\\n',\n",
       " 'tags': ['dp', 'number theory', 'math'],\n",
       " 'lang_cluster': 'C',\n",
       " 'src_uid': 'd3a0402de1338a1a542a86ac5b484acc',\n",
       " 'code_uid': '34184654fb16421248539e7699dd5232',\n",
       " 'difficulty': 1600,\n",
       " 'exec_outcome': 'PASSED',\n",
       " 'verdict': None,\n",
       " 'time': None,\n",
       " 'memory': None,\n",
       " 'sent': None,\n",
       " 'judged': None,\n",
       " 'id': None,\n",
       " 'submission_id': None,\n",
       " 'participant_id': None,\n",
       " 'code_length': 230,\n",
       " 'task_id': 'd3a0402de1338a1a542a86ac5b484acc',\n",
       " 'unittests': [{'exec_outcome': 'PASSED',\n",
       "   'input': '3\\n1 1 1\\n',\n",
       "   'output': ['YES'],\n",
       "   'result': 'YES'},\n",
       "  {'exec_outcome': 'PASSED',\n",
       "   'input': '6\\n1 0 1 1 1 0\\n',\n",
       "   'output': ['YES'],\n",
       "   'result': 'YES'},\n",
       "  {'exec_outcome': 'PASSED',\n",
       "   'input': '6\\n1 0 0 1 0 1\\n',\n",
       "   'output': ['NO'],\n",
       "   'result': 'NO'},\n",
       "  {'exec_outcome': 'PASSED',\n",
       "   'input': '10\\n1 0 1 1 1 0 1 0 1 0\\n',\n",
       "   'output': ['YES'],\n",
       "   'result': 'YES'},\n",
       "  {'exec_outcome': 'PASSED',\n",
       "   'input': '15\\n0 0 0 1 0 1 1 0 1 0 0 1 0 1 0\\n',\n",
       "   'output': ['YES'],\n",
       "   'result': 'YES'},\n",
       "  {'exec_outcome': 'PASSED',\n",
       "   'input': '29\\n0 1 0 0 0 1 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1\\n',\n",
       "   'output': ['NO'],\n",
       "   'result': 'NO'},\n",
       "  {'exec_outcome': 'PASSED',\n",
       "   'input': '77\\n0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 1 1 0 0 0 0 1 0 1 0 1 0 1 1 1\\n',\n",
       "   'output': ['YES'],\n",
       "   'result': 'YES'},\n",
       "  {'exec_outcome': 'PASSED',\n",
       "   'input': '99\\n1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\\n',\n",
       "   'output': ['YES'],\n",
       "   'result': 'YES'},\n",
       "  {'exec_outcome': 'PASSED',\n",
       "   'input': '18\\n0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0\\n',\n",
       "   'output': ['NO'],\n",
       "   'result': 'NO'},\n",
       "  {'exec_outcome': 'PASSED',\n",
       "   'input': '3\\n0 0 0\\n',\n",
       "   'output': ['NO'],\n",
       "   'result': 'NO'},\n",
       "  {'exec_outcome': 'PASSED',\n",
       "   'input': '3\\n0 0 1\\n',\n",
       "   'output': ['NO'],\n",
       "   'result': 'NO'},\n",
       "  {'exec_outcome': 'PASSED',\n",
       "   'input': '4\\n1 0 1 0\\n',\n",
       "   'output': ['NO'],\n",
       "   'result': 'NO'},\n",
       "  {'exec_outcome': 'PASSED',\n",
       "   'input': '4\\n0 1 0 1\\n',\n",
       "   'output': ['NO'],\n",
       "   'result': 'NO'},\n",
       "  {'exec_outcome': 'PASSED',\n",
       "   'input': '4\\n1 1 0 0\\n',\n",
       "   'output': ['NO'],\n",
       "   'result': 'NO'},\n",
       "  {'exec_outcome': 'PASSED',\n",
       "   'input': '4\\n1 1 1 1\\n',\n",
       "   'output': ['YES'],\n",
       "   'result': 'YES'},\n",
       "  {'exec_outcome': 'PASSED',\n",
       "   'input': '4\\n0 0 0 0\\n',\n",
       "   'output': ['NO'],\n",
       "   'result': 'NO'},\n",
       "  {'exec_outcome': 'PASSED',\n",
       "   'input': '4\\n1 0 1 1\\n',\n",
       "   'output': ['NO'],\n",
       "   'result': 'NO'},\n",
       "  {'exec_outcome': 'PASSED',\n",
       "   'input': '5\\n1 0 1 1 0\\n',\n",
       "   'output': ['NO'],\n",
       "   'result': 'NO'},\n",
       "  {'exec_outcome': 'PASSED',\n",
       "   'input': '5\\n1 1 1 1 1\\n',\n",
       "   'output': ['YES'],\n",
       "   'result': 'YES'},\n",
       "  {'exec_outcome': 'PASSED',\n",
       "   'input': '6\\n0 0 1 0 0 1\\n',\n",
       "   'output': ['NO'],\n",
       "   'result': 'NO'},\n",
       "  {'exec_outcome': 'PASSED',\n",
       "   'input': '6\\n0 1 0 0 0 0\\n',\n",
       "   'output': ['NO'],\n",
       "   'result': 'NO'},\n",
       "  {'exec_outcome': 'PASSED',\n",
       "   'input': '7\\n0 0 1 0 0 0 1\\n',\n",
       "   'output': ['NO'],\n",
       "   'result': 'NO'},\n",
       "  {'exec_outcome': 'PASSED',\n",
       "   'input': '7\\n1 1 1 1 1 1 1\\n',\n",
       "   'output': ['YES'],\n",
       "   'result': 'YES'},\n",
       "  {'exec_outcome': 'PASSED',\n",
       "   'input': '8\\n1 0 1 0 1 0 1 0\\n',\n",
       "   'output': ['YES'],\n",
       "   'result': 'YES'},\n",
       "  {'exec_outcome': 'PASSED',\n",
       "   'input': '15\\n0 0 1 0 0 1 0 0 1 0 0 1 0 0 1\\n',\n",
       "   'output': ['YES'],\n",
       "   'result': 'YES'},\n",
       "  {'exec_outcome': 'PASSED',\n",
       "   'input': '30\\n1 0 0 0 1 0 1 1 1 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0\\n',\n",
       "   'output': ['YES'],\n",
       "   'result': 'YES'},\n",
       "  {'exec_outcome': 'PASSED',\n",
       "   'input': '100\\n1 0 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 0 0 0 1 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 1 1 1 0 0\\n',\n",
       "   'output': ['YES'],\n",
       "   'result': 'YES'},\n",
       "  {'exec_outcome': 'PASSED',\n",
       "   'input': '113\\n1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\\n',\n",
       "   'output': ['YES'],\n",
       "   'result': 'YES'}],\n",
       " 'is_correct': 'True'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submi_ds = datasets.load_dataset(\"json\", data_files=str(sampled_submi_ds_path), split=\"train\")\n",
    "submi_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'YES'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submi_ds[0]['unittests'][0]['output'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_testcases(code_uid):\n",
    "    submi_ds = datasets.load_dataset(\"json\", data_files=str(sampled_submi_ds_path), split=\"train\")\n",
    "    for submi in submi_ds:\n",
    "        if submi['code_uid'] == code_uid:\n",
    "            return submi['unittests']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code(code_uid):\n",
    "    submi_ds = datasets.load_dataset(\"json\", data_files=str(sampled_submi_ds_path), split=\"train\")\n",
    "    for submi in submi_ds:\n",
    "        if submi['code_uid'] == code_uid:\n",
    "            return submi['source_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'exec_outcome': 'PASSED',\n",
       "  'input': '6 10\\nalloc 5\\nalloc 3\\nerase 1\\nalloc 6\\ndefragment\\nalloc 6\\n',\n",
       "  'output': ['1\\n2\\nNULL\\n3\\n'],\n",
       "  'result': '1\\n2\\nNULL\\n3'},\n",
       " {'exec_outcome': 'PASSED',\n",
       "  'input': '6 1\\ndefragment\\nalloc 10\\nalloc 1\\nerase -1\\nerase 1\\nerase 1\\n',\n",
       "  'output': ['NULL\\n1\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\n'],\n",
       "  'result': 'NULL\\n1\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT'},\n",
       " {'exec_outcome': 'PASSED',\n",
       "  'input': '14 100\\nalloc 99\\nalloc 1\\nalloc 1\\nerase 2\\nalloc 1\\nerase 4\\nerase 1\\nalloc 100\\nalloc 1\\nalloc 99\\ndefragment\\nerase 4\\nalloc 100\\nalloc 99\\n',\n",
       "  'output': ['1\\n2\\nNULL\\n3\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\n4\\nNULL\\nNULL\\nNULL\\n'],\n",
       "  'result': '1\\n2\\nNULL\\n3\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\n4\\nNULL\\nNULL\\nNULL'},\n",
       " {'exec_outcome': 'PASSED',\n",
       "  'input': '26 25\\ndefragment\\nerase 1\\nerase -1560200883\\nalloc 44\\ndefragment\\nalloc 75\\nalloc 22\\ndefragment\\nerase 4\\ndefragment\\nalloc 57\\nalloc 53\\nerase 4\\nerase -1639632026\\nerase -2121605039\\nerase 3\\nalloc 51\\nalloc 65\\ndefragment\\nerase 2\\nerase 4\\nalloc 52\\nerase 3\\ndefragment\\nerase -1842529282\\nerase 3\\n',\n",
       "  'output': ['ILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nNULL\\n1\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\n'],\n",
       "  'result': 'ILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nNULL\\n1\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT'},\n",
       " {'exec_outcome': 'PASSED',\n",
       "  'input': '22 9\\nerase 1\\nalloc 6\\nalloc 65\\nerase 1\\nalloc 87\\nerase -1638927047\\nalloc 5\\nerase 2\\nalloc 70\\ndefragment\\nalloc 20\\nalloc 48\\nerase -69401977\\nalloc 20\\ndefragment\\nerase 7\\ndefragment\\nerase 9\\nerase 7\\nerase 4\\ndefragment\\nalloc 66\\n',\n",
       "  'output': ['ILLEGAL_ERASE_ARGUMENT\\n1\\nNULL\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\n2\\nNULL\\nNULL\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\n'],\n",
       "  'result': 'ILLEGAL_ERASE_ARGUMENT\\n1\\nNULL\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\n2\\nNULL\\nNULL\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nNULL'},\n",
       " {'exec_outcome': 'PASSED',\n",
       "  'input': '12 40\\nerase 1\\nalloc 21\\nalloc 5\\nalloc 7\\ndefragment\\ndefragment\\nerase 2\\nalloc 83\\nerase 4\\ndefragment\\nalloc 59\\ndefragment\\n',\n",
       "  'output': ['ILLEGAL_ERASE_ARGUMENT\\n1\\n2\\n3\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\n'],\n",
       "  'result': 'ILLEGAL_ERASE_ARGUMENT\\n1\\n2\\n3\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nNULL'},\n",
       " {'exec_outcome': 'PASSED',\n",
       "  'input': '38 18\\nalloc 72\\nerase 2\\nalloc 50\\ndefragment\\nerase 3\\ndefragment\\nalloc 43\\nalloc 41\\ndefragment\\ndefragment\\nalloc 26\\nalloc 46\\nalloc 16\\nalloc 15\\ndefragment\\ndefragment\\nalloc 95\\nerase 7\\nerase 7\\nerase 5\\nerase 2\\nerase 9\\nerase 7\\nalloc 43\\ndefragment\\nerase 7\\ndefragment\\nalloc 48\\nalloc 77\\nerase 10\\nerase 11\\nalloc 16\\nalloc 84\\nerase 1\\ndefragment\\nalloc 86\\ndefragment\\nerase 13\\n',\n",
       "  'output': ['NULL\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nNULL\\nNULL\\nNULL\\n1\\nNULL\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nNULL\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\n'],\n",
       "  'result': 'NULL\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nNULL\\nNULL\\nNULL\\n1\\nNULL\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nNULL\\nNULL\\nILLEGAL_ERASE_ARGUMENT'},\n",
       " {'exec_outcome': 'PASSED',\n",
       "  'input': '37 74\\nalloc 11\\ndefragment\\nerase 1\\ndefragment\\nerase 2\\ndefragment\\nalloc 90\\nerase 3\\nerase 2\\nerase 3\\nerase 1\\nerase 1\\nalloc 38\\nalloc 19\\nerase 1\\nerase 3\\ndefragment\\nalloc 93\\nerase 5\\nerase 4\\nalloc 66\\nalloc 71\\nerase 5\\ndefragment\\ndefragment\\ndefragment\\ndefragment\\nerase 7\\nalloc 47\\nerase -95616683\\nerase 2\\nalloc 28\\nalloc 32\\nerase 11\\nalloc 50\\ndefragment\\ndefragment\\n',\n",
       "  'output': ['1\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\n2\\n3\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\n4\\n5\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\n'],\n",
       "  'result': '1\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\n2\\n3\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\n4\\n5\\nILLEGAL_ERASE_ARGUMENT\\nNULL'},\n",
       " {'exec_outcome': 'PASSED',\n",
       "  'input': '16 49\\nerase -751005193\\ndefragment\\nalloc 37\\nalloc 82\\nerase 3\\nerase 1\\nalloc 80\\nalloc 51\\ndefragment\\nalloc 74\\nerase 1\\nalloc 91\\ndefragment\\ndefragment\\nalloc 98\\ndefragment\\n',\n",
       "  'output': ['ILLEGAL_ERASE_ARGUMENT\\n1\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nNULL\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nNULL\\n'],\n",
       "  'result': 'ILLEGAL_ERASE_ARGUMENT\\n1\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nNULL\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nNULL'},\n",
       " {'exec_outcome': 'PASSED',\n",
       "  'input': '42 98\\ndefragment\\ndefragment\\ndefragment\\ndefragment\\ndefragment\\nalloc 5\\nalloc 66\\ndefragment\\nerase 3\\nalloc 53\\ndefragment\\nerase 4\\nerase 2\\nalloc 70\\nerase 3\\ndefragment\\ndefragment\\nerase 2\\nerase 3\\nerase -1327931832\\nalloc 93\\nalloc 64\\nerase 7\\nerase 6\\nerase 3\\nalloc 61\\nalloc 12\\nalloc 65\\nerase 2\\nalloc 46\\nerase 11\\nerase 9\\nerase 9\\nerase 6\\nalloc 2\\nalloc 78\\ndefragment\\nerase 13\\nerase 6\\nerase 10\\nalloc 53\\nalloc 46\\n',\n",
       "  'output': ['1\\n2\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\n3\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\n4\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nNULL\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nNULL\\n'],\n",
       "  'result': '1\\n2\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\n3\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\n4\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nNULL\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nNULL'},\n",
       " {'exec_outcome': 'PASSED',\n",
       "  'input': '19 46\\nalloc 21\\nerase 2\\nerase 1\\ndefragment\\nalloc 4\\ndefragment\\ndefragment\\nalloc 40\\nerase 1\\ndefragment\\ndefragment\\nalloc 68\\nerase -388966015\\nalloc 85\\nalloc 53\\nerase 4\\ndefragment\\nalloc 49\\nalloc 88\\n',\n",
       "  'output': ['1\\nILLEGAL_ERASE_ARGUMENT\\n2\\n3\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nNULL\\n'],\n",
       "  'result': '1\\nILLEGAL_ERASE_ARGUMENT\\n2\\n3\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nNULL'},\n",
       " {'exec_outcome': 'PASSED',\n",
       "  'input': '44 46\\nalloc 28\\nalloc 36\\ndefragment\\nerase -937404236\\nalloc 71\\ndefragment\\nalloc 81\\nalloc 51\\nerase 3\\ndefragment\\nalloc 48\\nerase 1\\ndefragment\\nalloc 36\\ndefragment\\ndefragment\\nerase 1\\ndefragment\\ndefragment\\nerase -1173350787\\nalloc 94\\nerase 5\\ndefragment\\nerase 9\\nalloc 98\\nerase 7\\ndefragment\\nerase 5\\nerase 1\\ndefragment\\nerase 2\\ndefragment\\nerase 4\\ndefragment\\nerase 9\\nalloc 8\\ndefragment\\nerase 9\\ndefragment\\ndefragment\\ndefragment\\nerase 1\\nalloc 70\\nerase 9\\n',\n",
       "  'output': ['1\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nNULL\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\n2\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\n3\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\n'],\n",
       "  'result': '1\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nNULL\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\n2\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\n3\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nILLEGAL_ERASE_ARGUMENT'},\n",
       " {'exec_outcome': 'PASSED',\n",
       "  'input': '26 25\\nalloc 25\\nerase 1\\nalloc 24\\nerase 2\\nalloc 23\\nerase 3\\nalloc 24\\nerase 4\\nalloc 24\\nerase 5\\nalloc 21\\nerase 6\\nalloc 24\\nerase 7\\nalloc 25\\nerase 8\\nalloc 25\\nerase 9\\nalloc 24\\nerase 10\\nalloc 25\\nerase 11\\nalloc 25\\nerase 12\\nalloc 25\\nerase 13\\n',\n",
       "  'output': ['1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n'],\n",
       "  'result': '1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13'},\n",
       " {'exec_outcome': 'PASSED',\n",
       "  'input': '22 9\\nalloc 9\\nerase 1\\nalloc 9\\nerase 2\\nalloc 9\\nerase 3\\nalloc 9\\nerase 4\\nalloc 9\\nerase 5\\nalloc 9\\nerase 6\\nalloc 9\\nerase 7\\nalloc 9\\nerase 8\\nalloc 9\\nerase 9\\nalloc 9\\nerase 10\\nalloc 9\\nerase 11\\n',\n",
       "  'output': ['1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n'],\n",
       "  'result': '1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11'},\n",
       " {'exec_outcome': 'PASSED',\n",
       "  'input': '7 6\\nalloc 1\\nalloc 2\\nalloc 3\\nerase 1\\ndefragment\\nerase 3\\nalloc 4\\n',\n",
       "  'output': ['1\\n2\\n3\\n4\\n'],\n",
       "  'result': '1\\n2\\n3\\n4'},\n",
       " {'exec_outcome': 'PASSED',\n",
       "  'input': '3 1\\nerase -1\\nerase 0\\nerase -2147483648\\n',\n",
       "  'output': ['ILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\n'],\n",
       "  'result': 'ILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT\\nILLEGAL_ERASE_ARGUMENT'},\n",
       " {'exec_outcome': 'PASSED',\n",
       "  'input': '7 100\\nalloc 100\\nerase 2147483647\\nerase 1\\nalloc 50\\nalloc 50\\nerase 3\\nerase -2147483648\\n',\n",
       "  'output': ['1\\nILLEGAL_ERASE_ARGUMENT\\n2\\n3\\nILLEGAL_ERASE_ARGUMENT\\n'],\n",
       "  'result': '1\\nILLEGAL_ERASE_ARGUMENT\\n2\\n3\\nILLEGAL_ERASE_ARGUMENT'},\n",
       " {'exec_outcome': 'PASSED',\n",
       "  'input': '12 10\\nalloc 6\\nalloc 2\\nerase 1\\nalloc 4\\nalloc 2\\nerase 3\\nalloc 2\\nalloc 3\\nalloc 1\\nalloc 1\\nalloc 1\\nalloc 1\\n',\n",
       "  'output': ['1\\n2\\n3\\n4\\n5\\nNULL\\n6\\n7\\n8\\n9\\n'],\n",
       "  'result': '1\\n2\\n3\\n4\\n5\\nNULL\\n6\\n7\\n8\\n9'},\n",
       " {'exec_outcome': 'PASSED',\n",
       "  'input': '8 50\\nalloc 51\\ndefragment\\nalloc 100\\ndefragment\\nerase 1\\nalloc 50\\ndefragment\\nalloc 50\\n',\n",
       "  'output': ['NULL\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\n1\\nNULL\\n'],\n",
       "  'result': 'NULL\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\n1\\nNULL'},\n",
       " {'exec_outcome': 'PASSED',\n",
       "  'input': '10 10\\nalloc 10\\nerase -1\\nerase 1\\nalloc 5\\nerase -1\\nalloc 5\\nerase 0\\nalloc 5\\nerase 0\\nalloc 5\\n',\n",
       "  'output': ['1\\nILLEGAL_ERASE_ARGUMENT\\n2\\nILLEGAL_ERASE_ARGUMENT\\n3\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\n'],\n",
       "  'result': '1\\nILLEGAL_ERASE_ARGUMENT\\n2\\nILLEGAL_ERASE_ARGUMENT\\n3\\nILLEGAL_ERASE_ARGUMENT\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\nNULL'},\n",
       " {'exec_outcome': 'PASSED',\n",
       "  'input': '16 10\\nalloc 10\\ndefragment\\ndefragment\\ndefragment\\nalloc 10\\nerase 1\\nerase 2\\nalloc 6\\ndefragment\\ndefragment\\nalloc 4\\ndefragment\\ndefragment\\nerase 3\\ndefragment\\nalloc 6\\n',\n",
       "  'output': ['1\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\n2\\n3\\nNULL\\n'],\n",
       "  'result': '1\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\n2\\n3\\nNULL'},\n",
       " {'exec_outcome': 'PASSED',\n",
       "  'input': '16 10\\nalloc 10\\ndefragment\\ndefragment\\ndefragment\\nalloc 10\\nerase 1\\nerase 2\\nalloc 6\\ndefragment\\ndefragment\\nalloc 4\\ndefragment\\ndefragment\\nerase 2\\ndefragment\\nalloc 6\\n',\n",
       "  'output': ['1\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\n2\\n3\\n4\\n'],\n",
       "  'result': '1\\nNULL\\nILLEGAL_ERASE_ARGUMENT\\n2\\n3\\n4'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_submi_ds_path = '/home/wyk/CodeLLMBenchmark/code_opt/code_performance_eval/dataset/screened_sampled_dataset_2023-09-20_17:52:54/sampled_submissions.jsonl'\n",
    "get_testcases('1d3a8804e288dee710091aedda77299c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_description(src_uid):\n",
    "    task_ds = datasets.load_dataset(\"json\", data_files=str(sampled_task_ds_path), split=\"train\")\n",
    "    for task in task_ds:\n",
    "        if task['src_uid'] == src_uid:\n",
    "            return task['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n = int(input())\\na = list(map(int, input().split()))\\nm = int(input())\\nbf = list(map(int,input().split()))\\nb = bf[::-1]\\nrt = 0\\nlt = {}\\nfor i in a:\\n    for j in b:\\n        if j/i >= rt and j%i == 0:\\n            rt = j/i\\n            if rt in lt.keys():\\n                lt[rt] += 1\\n            else:\\n                lt[rt] = 1\\n#print(lt)\\nres = max(lt ,key = int)\\nprint(lt[res])'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_code('1b7a2be826dca647e28f51af4015e53b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAs an expert software developer with years of experience, please meticulously inspect the following low performance code sample and give a optimized version of the code, making it implement the same exact function but achieve faster execution time or smaller memory usage. The generated optimized version of code should strictly follow the same dependencies information and input output logic as the sample source code.\\nThe detailed information are as follows:\\n1. Description of the task which the sample code solves: Vasya\\'s bicycle chain drive consists of two parts: n stars are attached to the pedal axle, m stars are attached to the rear wheel axle. The chain helps to rotate the rear wheel by transmitting the pedal rotation.We know that the i-th star on the pedal axle has ai (0<a1<a2<...<an) teeth, and the j-th star on the rear wheel axle has bj (0<b1<b2<...<bm) teeth. Any pair (i,j) (1≤i≤n;\\xa01≤j≤m) is called a gear and sets the indexes of stars to which the chain is currently attached. Gear (i,j) has a gear ratio, equal to the value .Since Vasya likes integers, he wants to find such gears (i,j), that their ratios are integers. On the other hand, Vasya likes fast driving, so among all \"integer\" gears (i,j) he wants to choose a gear with the maximum ratio. Help him to find the number of such gears.In the problem, fraction  denotes division in real numbers, that is, no rounding is performed.\\n2. sample source code: \\n```\\nn = int(input())\\na = list(map(int, input().split()))\\nm = int(input())\\nbf = list(map(int,input().split()))\\nb = bf[::-1]\\nrt = 0\\nlt = {}\\nfor i in a:\\n    for j in b:\\n        if j/i >= rt and j%i == 0:\\n            rt = j/i\\n            if rt in lt.keys():\\n                lt[rt] += 1\\n            else:\\n                lt[rt] = 1\\n#print(lt)\\nres = max(lt ,key = int)\\nprint(lt[res])\\n```\\nRespond only with a string in the following JSON format:\\n{\"can_be_optimized\": True or False, \"optimization_ideas\": ideas string, “optimized_code”: code string}\\n'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_code = get_code('1b7a2be826dca647e28f51af4015e53b')\n",
    "task_description = get_task_description('102667eaa3aee012fef70f4192464674')\n",
    "prompt = f\"\"\"\n",
    "As an expert software developer with years of experience, please meticulously inspect the following low performance code sample and give a optimized version of the code, making it implement the same exact function but achieve faster execution time or smaller memory usage. The generated optimized version of code should strictly follow the same dependencies information and input output logic as the sample source code.\n",
    "The detailed information are as follows:\n",
    "1. Description of the task which the sample code solves: {task_description}\n",
    "2. sample source code: \n",
    "```\n",
    "{sample_code}\n",
    "```\n",
    "Respond only with a string in the following JSON format:\n",
    "{{\"can_be_optimized\": True or False, \"optimization_ideas\": ideas string, “optimized_code”: code string}}\n",
    "\"\"\"\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "As an expert software developer with years of experience, please meticulously inspect the following low performance code sample and give a optimized version of the code, making it implement the same exact function but achieve faster execution time or smaller memory usage. The generated optimized version of code should strictly follow the same dependencies information and input output logic as the sample source code.\n",
      "The detailed information are as follows:\n",
      "1. Description of the task which the sample code solves: Vasya's bicycle chain drive consists of two parts: n stars are attached to the pedal axle, m stars are attached to the rear wheel axle. The chain helps to rotate the rear wheel by transmitting the pedal rotation.We know that the i-th star on the pedal axle has ai (0<a1<a2<...<an) teeth, and the j-th star on the rear wheel axle has bj (0<b1<b2<...<bm) teeth. Any pair (i,j) (1≤i≤n; 1≤j≤m) is called a gear and sets the indexes of stars to which the chain is currently attached. Gear (i,j) has a gear ratio, equal to the value .Since Vasya likes integers, he wants to find such gears (i,j), that their ratios are integers. On the other hand, Vasya likes fast driving, so among all \"integer\" gears (i,j) he wants to choose a gear with the maximum ratio. Help him to find the number of such gears.In the problem, fraction  denotes division in real numbers, that is, no rounding is performed.\n",
      "2. sample source code: \n",
      "```\n",
      "n = int(input())\n",
      "a = list(map(int, input().split()))\n",
      "m = int(input())\n",
      "bf = list(map(int,input().split()))\n",
      "b = bf[::-1]\n",
      "rt = 0\n",
      "lt = {}\n",
      "for i in a:\n",
      "    for j in b:\n",
      "        if j/i >= rt and j%i == 0:\n",
      "            rt = j/i\n",
      "            if rt in lt.keys():\n",
      "                lt[rt] += 1\n",
      "            else:\n",
      "                lt[rt] = 1\n",
      "#print(lt)\n",
      "res = max(lt ,key = int)\n",
      "print(lt[res])\n",
      "```\n",
      "Respond only with a string in the following JSON format:\n",
      "{\"can_be_optimized\": True or False, \"optimization_ideas\": ideas string, “optimized_code”: code string}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
